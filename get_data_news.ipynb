{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300587 运行完成\n",
      "603185 运行完成\n",
      "600674 运行完成\n",
      "002203 运行完成\n",
      "601127 运行完成\n",
      "002597 运行完成\n",
      "603348 运行完成\n",
      "300487 运行完成\n",
      "603876 运行完成\n",
      "601677 运行完成\n",
      "300655 运行完成\n",
      "002078 运行完成\n",
      "002738 运行完成\n",
      "002812 运行完成\n",
      "603596 运行完成\n",
      "300332 运行完成\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "def get_url(code,pages):\n",
    "    '''\n",
    "    获取东方财富网股吧链接列表\n",
    "    code是指公司代码\n",
    "    page是值爬取页数\n",
    "    '''\n",
    "    url_list = []\n",
    "    for page in range(1,pages+1):\n",
    "        url = f\"http://guba.eastmoney.com/list,{code},1,f_{page}.html\"\n",
    "        url_list.append(url)\n",
    "        \n",
    "    return url_list\n",
    "\n",
    "def get_news(url_list,code):\n",
    "    '''\n",
    "    获取东方财富网新闻列表至本地xls\n",
    "    url_list是指链接列表\n",
    "    '''\n",
    "    headers = {\n",
    "        # 'User-Agent': UserAgent(verify_ssl=False).random,\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36',\n",
    "        'cookie': 'qgqp_b_id=b90ae58b50ba4b8868c1988b80823e4c; st_si=62771611099798; st_asi=delete; st_pvi=50748890314615; st_sp=2022-10-24 11:22:01; st_inirUrl=http://guba.eastmoney.com/list,hk01810,1,f_1.html; st_sn=2; st_psi=20221024112234183-117001300541-9748756866'\n",
    "    }\n",
    "    \n",
    "    # 保存爬取内容\n",
    "    outwb = openpyxl.Workbook() # 打开一个将写的文件\n",
    "    outws = outwb.create_sheet(index=0) # 在将写的文件创建sheet\n",
    "    outws.cell(row = 1, column = 1, value = \"read\")\n",
    "    outws.cell(row = 1, column = 2, value = \"comment\")\n",
    "    outws.cell(row = 1, column = 3, value = \"title\")\n",
    "    outws.cell(row = 1, column = 4, value = \"author\")\n",
    "    outws.cell(row = 1, column = 5, value = \"renew\")\n",
    "    outws.cell(row = 1, column = 6, value = \"link\")\n",
    "    index = 2\n",
    "    \n",
    "    for i in range(len(url_list)):\n",
    "        url = url_list[i]\n",
    "        res = requests.get(url,headers = headers)\n",
    "        res.encoding = res.apparent_encoding\n",
    "        html = res.text\n",
    "        soup = BeautifulSoup(html,\"html.parser\")\n",
    "        read_list = soup.select(\".l1.a1\")[1:]\n",
    "        comment_list = soup.select(\".l2.a2\")[1:]\n",
    "        title_list = soup.select(\".l3.a3\")[1:]\n",
    "        author_list = soup.select(\".l4.a4\")[1:]\n",
    "        renew_list = soup.select(\".l5.a5\")[1:]\n",
    "        for k in range(len(title_list)):\n",
    "            outws.cell(row = index, column = 1, value = str(read_list[k].text.strip()))\n",
    "            outws.cell(row = index, column = 2, value = str(comment_list[k].text.strip()))\n",
    "            outws.cell(row = index, column = 3, value = str(title_list[k].select('a')[0][\"title\"]))\n",
    "            outws.cell(row = index, column = 4, value = str(author_list[k].text.strip()))\n",
    "            outws.cell(row = index, column = 5, value = str(renew_list[k].text.strip()))\n",
    "            outws.cell(row = index, column = 6, value = str(title_list[k].select('a')[0][\"href\"]))                                                \n",
    "            index += 1\n",
    "            # print(title_list[k].select('a')[0][\"title\"],renew_list[k].text.strip())\n",
    "        time.sleep(random.uniform(3,4))\n",
    "            \n",
    "    outwb.save(f\"./news/{code}.xlsx\")\n",
    "\n",
    "\n",
    "# code = \"hk01810\"\n",
    "# code = \"603355\"\n",
    "# pages = 5\n",
    "# url_list = get_url(code,pages)\n",
    "# get_news(url_list,code)\n",
    "# print(\"运行完成\")    \n",
    "\n",
    "stk_code_list = ['300587.SZ',\n",
    "'603185.SH',\n",
    "'600674.SH',\n",
    "'002203.SZ',\n",
    "'601127.SH',\n",
    "'002597.SZ',\n",
    "'603348.SH',\n",
    "'300487.SZ',\n",
    "'603876.SH',\n",
    "'601677.SH',\n",
    "'300655.SZ',\n",
    "'002078.SZ',\n",
    "'002738.SZ', #2022-10-14新增4个对子\n",
    "'002812.SZ',\n",
    "'603596.SH',\n",
    "'300332.SZ',]\n",
    "for stk_code in stk_code_list:\n",
    "    code = stk_code.split('.')[0]\n",
    "    pages = 5\n",
    "    url_list = get_url(code,pages)\n",
    "    get_news(url_list,code)\n",
    "    print(f\"{code} 运行完成\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://guba.eastmoney.com/list,300332,1,f_1.html',\n",
       " 'http://guba.eastmoney.com/list,300332,1,f_2.html',\n",
       " 'http://guba.eastmoney.com/list,300332,1,f_3.html',\n",
       " 'http://guba.eastmoney.com/list,300332,1,f_4.html',\n",
       " 'http://guba.eastmoney.com/list,300332,1,f_5.html']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b7a3c99c09164ed3315a85b9be868456d78d186d21965e8a7155bab558fd18f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
